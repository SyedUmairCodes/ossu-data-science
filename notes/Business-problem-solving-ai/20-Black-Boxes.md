Machine learning models are like black boxes. They are trained on data sets and make predictions based on patterns they detect in the data. It is often difficult to understand how these models make their decisions.

This can be a problem when these models are used for tasks that have a direct impact on people's lives, such as analyzing or predicting aspects of someone's work performance, reliability, behavior, personal preferences, interests, health, economic situation, location, or movements.

Traditional approaches to computer programming might accomplish such tasks through well-defined rules that have been directly coded by a programmer. 

> These rules are relatively easy to list, describe, and explain, making it possible to provide a reasonable level of transparency.

Machine learning models, on the other hand, function more like a black box, making it harder to pinpoint the actual rules the model has developed to perform the task. This could make it very difficult to meet transparency requirements set by regulations such as the General Data Protection Regulation (GDPR).